{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 demo/quiz\n",
    "Let's talk categorization! In particular, let's see how a formal simulation of the exemplar model provides a very simple yet unintuitive prediction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Mack et al. (2013) study, participants learned to categorize simple visual objects into one of two categories. The objects were composed of four different dimensions (size, color, shape, position), each of which had two values. The categories were structured such that there are 5 objects in category A and 4 in category B:\n",
    "\n",
    "![objects](https://dl.dropboxusercontent.com/s/331ax1b36mpup6q/objects.png)\n",
    "\n",
    "These different feature values along the four dimensions can be represented as a binary variable. By doing so, each object is defined by a vector of four values. For example, a small, green, circle, on the left is defined as [1,1,1,1]. A large, red, triangle, on the right is defined as [0,0,0,0]. All of the nine objects are defined in this way below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "catA = np.array([[0.5,1],[1,0.5],[1,1.5],[1.5,1]])\n",
    "protoA = np.array([1,1])\n",
    "catB = np.array([[1.5,2],[2,1.5],[2,2.5],[2.5,2]])\n",
    "protoB = np.array([2,2])\n",
    "items = np.append(catA,catB,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplar model's summed similarity\n",
    "Let's fit the exemplar model to this data! The exemplar model makes a category decision by first calculating the summed similarity between a test object and the category exemplars. Summed similarity is based on Shepard's exponential generalization function and requires computing the distance between the test item and each category exemplar, summing these distances, and computing similarity with the exponential function. One important thing to note is that the exemplar model assumes we selectively attend to the stimulus dimensions that are most informative for making a category decision. This is modeled as a set of weights on the stimulus dimensions and is defined in the formula as the `w` parameter. Here's the formula for summed similarity between a test item `i` and category A:\n",
    "\n",
    "![summed similarity](https://dl.dropboxusercontent.com/s/8hphlyff2o426by/ss.png)\n",
    "\n",
    "Below is defined a function that calculates summed similarity between a test object (`item`) and exemplars from a category (`catitems`) given a set of parameters (attention weights `w`, distance power value `r`, and exponential scaling parameter `c`). This function is intact (i.e., no code for you to add) and we will use this later in an exemplar model function. But, before that, let's see how the summed similarity function works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summed_similarity(w,r,c,item,catitems):\n",
    "    distances = np.sum(np.array(w*[np.abs(item-x)**r for x in catitems]),axis=1)**(1/r)\n",
    "    similarities = np.exp(-c*distances)\n",
    "    ss = np.sum(similarities)\n",
    "    return(ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see what the summed similarity is between the object defined by [0,0,0,0] and the category A exemplars. We will assume the attention weights are equal across all the dimensions and `c` is equal to 1. Given the dimensions of these stimuli, what should `r` be set to (remember, `r=1` gives a city block distance, `r=2` gives a Euclidean distance)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "w = np.array([1,1])\n",
    "r = 2\n",
    "c = 1\n",
    "ssA = summed_similarity(w,r,c,[1,1],protoA)\n",
    "print(ssA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result above should be approximately 1.6068. If not, check how you set the `r` parameter. \n",
    "\n",
    "Now, calculate the summed similarity between the same object and the category B exemplars with the same parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33877327373\n"
     ]
    }
   ],
   "source": [
    "ssB = summed_similarity(w,r,c,testobject,catB) #??\n",
    "print ssB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which category is the test object more similar to? Double click on this cell to make it editable, then add your answer below.\n",
    "\n",
    "** Provide your answer here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above calculations assume that all dimensions receive the same attention (i.e., they are given the same weight). Try downweighting different dimensions (e.g., setting `w` equal to `np.array([0,1,1,1])` removes all attention from dimension 1 in the summed similarity calculations) to see if you can maximize the summed similarity between the test object and category A and minimize summed similarity to category B:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-84dd48adc339>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-84dd48adc339>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    ssB = ?? # fill in from above\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "w = np.array([1,1,1,1])\n",
    "ssA = summed_similarity(w,r,c,testobject,catA)\n",
    "ssB = ?? # fill in from above\n",
    "print ssA, ssB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting response probabilities with the exemplar model\n",
    "In the exemplar model, the probability of making a category response depends on a ratio of the summed similarity to that category and the total summed similarity to all categories. Here's the formula:\n",
    "\n",
    "![probability of 'A'](https://dl.dropboxusercontent.com/s/oje1nwd2v7r237h/probA.png)\n",
    "\n",
    "Below, we need to fill in code in the `exemplar_model` function to get these response probability predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exemplar_model(w,r,c,items,catA,catB):\n",
    "    # attention weights to the four dimensions should sum to 1\n",
    "    w = w/sum(w)\n",
    "    \n",
    "    # power value in distance calculation: 1 = city block, 2 = Euclidean\n",
    "    r = 1 # given the dimensions of the objects, what should this be???\n",
    "    \n",
    "    # loop through each study item to get the exemplar model prediction\n",
    "    probA = np.array([])\n",
    "    for item in items:\n",
    "        \n",
    "        # calculate summed similarity between item and category A exemplars\n",
    "        ssA = summed_similarity(w,r,c,item,catA) #??\n",
    "        # calculate summed similarity between item and category B exemplars\n",
    "        ssB = summed_similarity(w,r,c,item,catB) #??\n",
    "        # calculate the probability of making an 'A' category response\n",
    "        pA = ssA/(ssA+ssB) #??\n",
    "\n",
    "        # store the result\n",
    "        probA = np.append(probA,pA)\n",
    "        \n",
    "    return probA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.array([1,1,0,1])\n",
    "c = 4\n",
    "r = 1 #?? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.55555556  0.55555556  0.55555556  0.55555556  0.55555556  0.55555556\n",
      "  0.55555556  0.55555556  0.55555556]\n"
     ]
    }
   ],
   "source": [
    "pred_prob = exemplar_model(w,r,c,studyitems,catA,catB)\n",
    "print pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exemplar_model_fitting(parameters):\n",
    "    w = np.array([parameters[0],parameters[1],parameters[2],parameters[3]])\n",
    "    c = parameters[4]\n",
    "    r = 1\n",
    "    probA = exemplar_model(w,r,c,studyitems,catA,catB)\n",
    "    sse = np.sum((obs_prob-probA)**2)**0.5\n",
    "    return sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'optimize'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-62ebd333e103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexemplar_model_fitting\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfitresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexemplar_model_fitting\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'optimize'"
     ]
    }
   ],
   "source": [
    "import scipy\n",
    "scipy.optimize.minimize(exemplar_model_fitting,parameters)\n",
    "fitresult = sp.optimize.minimize(exemplar_model_fitting,parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob = exemplar_model(fitresult.x,studyitems,catA,catB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79890107,  0.86189709,  0.82438152,  0.94737339,  0.78226414,\n",
       "        0.33431939,  0.26022669,  0.1944971 ,  0.07039132])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f787333aad0>]"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAEACAYAAABI5zaHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/weS6efWmrMl2gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f787333a7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(1,10)\n",
    "width = 0.8\n",
    "plt.bar(x-0.4,obs_prob)\n",
    "plt.plot(x,pred_prob,'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.37365952,  1.01305954,  0.39714224,  1.34183837,  5.6472406 ,\n",
       "        1.15      ])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitresult.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "psy471",
   "language": "python",
   "name": "psy471"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
